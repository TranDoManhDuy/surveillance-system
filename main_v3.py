import torch
import cv2
import time
import numpy as np
import argparse
import os
import math
from collections import defaultdict, deque
from scipy.optimize import linear_sum_assignment
class PersonTracker:
    def __init__(self, model_name='yolov5m', confidence_threshold=0.5, device=None):
        """
        Initialize the person tracker with distance monitoring
        
        Args:
            model_name (str): YOLOv5 model variant
            confidence_threshold (float): Minimum confidence for detection
            device (str): Device to run on
        """
        self.confidence_threshold = confidence_threshold
        self.device = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')
        
        # Load YOLOv5 model
        print(f"Loading {model_name} model on {self.device}...")
        self.model = torch.hub.load('ultralytics/yolov5', model_name)
        self.model.to(self.device)
        self.model.eval() # b·∫≠t ch·∫ø ƒë·ªô ƒë√°nh gi√°
        
        # Tracking variables
        self.tracks = {}  # {track_id: Track object} - l∆∞u tr·ªØ th√¥ng tin c·ªßa c√°c object ƒëang ƒë∆∞·ª£c theo d√µi, c√°c ƒë·ªëi t∆∞·ª£ng n√†y ƒë√£ ƒë∆∞·ª£c ƒë√°nh ID
        self.next_id = 1
        self.max_disappeared = 30  # Max frames before removing track
        self.max_distance = 100   # Max distance for matching detections 
        # l√† ng∆∞·ª°ng kho·∫£ng c√°ch t·ªëi ƒëa (t√≠nh b·∫±ng pixel) ƒë∆∞·ª£c cho ph√©p gi·ªØa m·ªôt track ƒëang theo d√µi v√† m·ªôt detection m·ªõi ƒë·ªÉ h·ªá th·ªëng coi ƒë√≥ l√† c√πng m·ªôt ng∆∞·ªùi (matching).
        
        # Distance monitoring parameters
        self.PERSON_HEIGHT_REAL = 1.7  # meters - chi·ªÅu cao m·∫∑c ƒë·ªãnh 1 ng∆∞·ªùi, m√¥ ph·ªèng
        self.SOCIAL_DISTANCE_THRESHOLD = 2.0  # meters - Kho·∫£ng c√°ch gi√£n c√°ch x√£ h·ªôi
        self.WARNING_DURATION = 1  # seconds - th·ªùi gian m√† 2 ng∆∞·ªùi g·∫ßn nhau t·ªëi ƒëa tr∆∞·ªõc khi c·∫£nh b√°o vang l√™n
        
        # Performance tracking
        self.frame_count = 0
        self.total_time = 0
        self.current_fps = 30  # Default FPS, will be updated from video
        
        # Distance tracking
        self.distance_history = defaultdict(lambda: deque(maxlen=3000))  # 50fps * 60s = 3000 frames/ m·ª•c ƒë√≠ch ƒë·ªÉ l∆∞u l·∫°i kho·∫£ng c√°ch gi·ªØa 2 ng∆∞·ªùi theo th·ªùi gian.
        self.warned_pairs = set()  # Track pairs that have been warned
        
        # Colors for different IDs
        self.colors = self._generate_colors(50)
        self.available_ids = deque()
    def _generate_colors(self, n):
        """Generate n distinct colors for tracking visualization"""
        colors = []
        for i in range(n):
            hue = i / n
            rgb = tuple(int(c * 255) for c in self._hsv_to_rgb(hue, 0.8, 0.9))
            colors.append(rgb)
        return colors
    
    def _hsv_to_rgb(self, h, s, v):
        """Convert HSV to RGB"""
        import colorsys
        return colorsys.hsv_to_rgb(h, s, v)
    
    def set_fps(self, fps):
        """Set the video FPS for accurate timing"""
        self.current_fps = fps
        # Update deque maxlen based on FPS
        max_frames = int(fps * self.WARNING_DURATION)
        self.distance_history = defaultdict(lambda: deque(maxlen=max_frames))
    
    def detect_persons(self, frame):
        """Detect persons in frame"""
        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        start_time = time.time()
        results = self.model(img, size=640)
        inference_time = time.time() - start_time
        
        self.frame_count += 1
        self.total_time += inference_time
        
        # Extract person detections
        detections = []
        preds = results.pred[0] # l·∫•y ra c√°c d·ª± ƒëo√°n v·ªÅ con ng∆∞·ªùi - ƒë·ªãnh d·∫°ng torch.tensor([N, 6]), v√† ƒë∆∞∆°ng nhi√™n l·∫•y ra t·∫•m ·∫£nh ƒë·∫ßu ti√™n trong batch
        for *xyxy, conf, cls in preds: # Th·ª© t·ª± c√°c ph·∫ßn t·ª≠ ƒë∆∞·ª£c d·ª± ƒëo√°n - xyxy conf clss
            if int(cls) == 0 and conf > self.confidence_threshold:  # Person class - l·∫•y ng∆∞·ªùi v√† l·∫•y nh·ªØng d·ª± ƒëo√°n c√≥ conf > threshold
                x1, y1, x2, y2 = map(int, xyxy)
                center_x = (x1 + x2) // 2
                center_y = (y1 + y2) // 2
                width = x2 - x1
                height = y2 - y1
                
                detections.append({
                    'bbox': (x1, y1, x2, y2),
                    'center': (center_x, center_y),
                    'confidence': float(conf),
                    'area': width * height,
                    'height_pixels': height  # Store pixel height for distance calculation
                })
        # Tr·∫£ ra 1 list c√°c d·ª± ƒëo√°n
        return detections, inference_time
    
    def calculate_pixel_distance(self, center1, center2):
        """Calculate Euclidean distance between two centers in pixels"""
        return math.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)
    
    def calculate_real_distance(self, center1, center2, height1_pixels, height2_pixels):
        """
        Calculate real-world distance between two persons based on their pixel heights
        
        Args:
            center1, center2: Center coordinates of the two persons
            height1_pixels, height2_pixels: Heights in pixels of the two persons
            
        Returns:
            Real distance in meters
        """
        # Average height in pixels
        avg_height_pixels = (height1_pixels + height2_pixels) / 2
        
        # Calculate pixels per meter ratio
        pixels_per_meter = avg_height_pixels / self.PERSON_HEIGHT_REAL
        
        # Calculate pixel distance
        pixel_distance = self.calculate_pixel_distance(center1, center2)
        
        # Convert to real distance
        real_distance = pixel_distance / pixels_per_meter
        
        return real_distance
    
    def calculate_iou(self, box1, box2):
        """Calculate Intersection over Union (IoU) of two bounding boxes"""
        x1_1, y1_1, x2_1, y2_1 = box1
        x1_2, y1_2, x2_2, y2_2 = box2
        
        # Calculate intersection area
        x1_i = max(x1_1, x1_2)
        y1_i = max(y1_1, y1_2)
        x2_i = min(x2_1, x2_2)
        y2_i = min(y2_1, y2_2)
        
        if x2_i <= x1_i or y2_i <= y1_i:
            return 0.0
        
        intersection = (x2_i - x1_i) * (y2_i - y1_i)
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0
    
    # nh·∫≠n v√†o ƒë·∫ßu ra c·ªßa h√†m detect_human
    # detections.append({
    #                 'bbox': (x1, y1, x2, y2),
    #                 'center': (center_x, center_y),
    #                 'confidence': float(conf),
    #                 'area': width * height,
    #                 'height_pixels': height  # Store pixel height for distance calculation
    #             })
    def update_tracks(self, detections):
        """Update tracks using Hungarian algorithm"""
        track_ids = list(self.tracks.keys()) # danh s√°ch c√°c keys (id) c·ªßa c√°c ƒë·ªëi t∆∞·ª£ng ƒëang ƒë∆∞·ª£c theo d√µi
        num_tracks = len(track_ids) # s·ªë l∆∞·ª£ng ƒë·ªëi t∆∞·ª£ng ƒëang ƒë∆∞·ª£c theo d√µi
        num_detections = len(detections) # s·ªë l∆∞·ª£ng ƒë·ªëi t∆∞·ª£ng m·ªõi ƒë∆∞·ª£c ph√°t hi·ªán trong khung h√¨nh v·ª´a r·ªìi

        if num_tracks == 0:
            for detection in detections:
                self.tracks[self.next_id] = Track(self.next_id, detection) # kh·ªüi t·∫°o ƒë·ªëi t∆∞·ª£ng theo d√µi m·ªõi v√† th√™m v√† danh s√°ch c√°c ƒë·ªëi t∆∞·ª£ng theo d√µi.
                self.next_id += 1 # tƒÉng ID l√™n.
            return

        # ma tr·∫≠n chi ph√≠ trong qu√° tr√¨nh g√°n detection m·ªõi cho c√°c tracking ƒë√£ theo d√µi - s·ª≠ d·ª•ng 
        # trong thu·∫≠t to√°n hungarian
        cost_matrix = np.zeros((num_tracks, num_detections), dtype=np.float32)
        for i, track_id in enumerate(track_ids): # l·∫∑p qua t·ª´ng c√°c key c·ªßa c√°c track ƒëang ƒë∆∞·ª£c theo d√µi
            track = self.tracks[track_id] # l·∫•y ra track
            for j, detection in enumerate(detections): # l·∫∑p qua c√°c d·ª± ƒëo√°n
                # i, j l√† c√°c v·ªã tr√≠ t∆∞∆°ng ·ª©ng tr√™n ma tr·∫≠n chi ph√≠.
                
                # kho·∫£ng c√°ch eudiance gi·ªØa detection m·ªõi v·ªõi v·ªã tr√≠ m·ªõi nh·∫•t c·ªßa ƒë·ªëi t∆∞·ª£ng ƒë√£ ƒë∆∞·ª£c theo d√µi l∆∞u trong track
                distance = self.calculate_pixel_distance(track.center, detection['center'])
                
                # t√≠nh IoU gi·ªØa detection m·ªõi v·ªõi v·ªã tr√≠ m·ªõi nh·∫•t c·ªßa ƒë·ªëi t∆∞·ª£ng ƒë√£ ƒë∆∞·ª£c theo d√µi l∆∞u trong track
                iou = self.calculate_iou(track.bbox, detection['bbox'])
                cost = distance - (iou * 50) # c√≥ th·ªÉ thay 50 b·∫±ng gi√° tr·ªã kh√°c, t√πy thu·ªôc ƒë·ªô ∆∞u ti√™n IoU so v·ªõi distance
                cost_matrix[i, j] = cost

        # Hungarian Algorithm Input: cost_matrix c√≥ shape [num_tracks, num_detections], 
        # m·ªói ph·∫ßn t·ª≠ l√† chi ph√≠ g√°n gi·ªØa m·ªôt track v√† m·ªôt detection.
        row_ind, col_ind = linear_sum_assignment(cost_matrix)
        assigned_tracks = set() # ch·ªâ s·ªë h√†ng (track index).
        assigned_detections = set() # ch·ªâ s·ªë c·ªôt (detection index).
        # Gh√©p (row_ind[i], col_ind[i]) s·∫Ω cho b·∫°n c·∫∑p track‚Äìdetection t·ªëi ∆∞u.

        for i, j in zip(row_ind, col_ind): # l·∫∑p qua t·ª´ng √¥ c·ªßa m·∫£ng chi ph√≠
            if cost_matrix[i, j] < self.max_distance: # lo·∫°i b·ªè c√°c match c√≥ chi ph√≠ v∆∞·ª£t ng∆∞·ª°ng
                track_id = track_ids[i] # l·∫•y ra id c·ªßa track ƒëang ƒë∆∞·ª£c theo d√µi
                self.tracks[track_id].update(detection=detections[j]) # c·∫≠p nh·∫≠t
                assigned_tracks.add(track_id) # ƒë√°nh d·∫•u c√°c track ƒë√£ match th√†nh c√¥ng r·ªìi. th√¥ng qua id c·ªßa n√≥
                assigned_detections.add(j) # ƒë√°nh d·∫•u c√°c detect ƒë√£ ƒë∆∞·ª£c match qua th·ª© t·ª± c·ªßa n√≥

        # Increase disappeared count for unmatched tracks - c·∫≠p nh·∫≠t s·ªë l∆∞·ª£ng frame li√™n ti·∫øp ko ƒë∆∞·ª£c detect c·ªßa c√°c ƒë·ªëi t∆∞·ª£ng ƒë√£ ƒë∆∞·ª£c theo d√µi tr∆∞·ªõc ƒë√≥.
        for i, track_id in enumerate(track_ids):
            if track_id not in assigned_tracks:
                self.tracks[track_id].disappeared += 1

        # Add new tracks for unmatched detections
        for j, detection in enumerate(detections):
            if j not in assigned_detections: # xem c√°c detect n√†o m√† ch∆∞a c√≥ track n√†o theo d√µi, t·ª©c l√† ƒë·ªëi t∆∞·ª£ng m·ªõi.
                if self.available_ids: # ki·ªÉm tra danh s√°ch c√°c ID s·∫µn s√†ng
                    reuse_id = self.available_ids.popleft()
                else:
                    reuse_id = self.next_id
                    self.next_id += 1
                self.tracks[reuse_id] = Track(reuse_id, detection) # th√™m track m·ªõi, track v·ª´a ƒë∆∞·ª£c kh·ªüi t·∫°o nh·∫±m theo d√µi c√°c ƒë·ªëi t∆∞·ª£ng m·ªõi.

        # Remove disappeared tracks
        to_remove = [track_id for track_id, t in self.tracks.items() if t.disappeared > self.max_disappeared] # b·ªè ƒëi c√°c track m√† s·ªë l·∫ßn li√™n ti·∫øp ƒë·ªëi 
        # t∆∞·ª£ng c·ªßa track ƒë√≥ ƒë√£ kh√¥ng xu·∫•t hi·ªán v∆∞·ª£t qua ng∆∞·ª°ng ƒë√£ qua ƒë·ªãnh tr∆∞·ªõc
        for track_id in to_remove: # track n√†o b·ªã remove th√¨ l·∫•y l·∫°i ID c·ªßa track ƒë√≥.
            del self.tracks[track_id]
            self.available_ids.append(track_id)  # Mark ID as reusable  
    
    # t√≠nh to√°n kho·∫£ng c√°ch gi·ªØa c√°c ƒë·ªëi t∆∞·ª£ng
    def monitor_distances(self):
        """Monitor distances between all active tracks"""
        active_tracks = [(tid, track) for tid, track in self.tracks.items() if track.disappeared == 0] # L·ªçc ra c√°c track m√† ƒë·ªëi t∆∞·ª£ng c·ªßa n√≥ ch∆∞a bi·∫øn m·∫•t
        # t·ª©c l√† c√°c track m√† bbox c·ªßa v·∫≠t th·ªÉ c√≤n n·∫±m tr√™n khung h√¨nh
        
        # close_pairs.append((id1, id2, real_distance))
        close_pairs = [] # l∆∞u l·∫°i c·∫∑p ID c·ªßa 2 track, v√† kho·∫£ng c√°ch 2 ƒë·ªëi t∆∞·ª£ng trong 2 track ƒë√≥, ·ªü frame h√¨nh m·ªõi nh·∫•t c·ªßa 2 track
        
        for i, (id1, track1) in enumerate(active_tracks):
            for j, (id2, track2) in enumerate(active_tracks):
                if i >= j:  # Avoid duplicate pairs and self-comparison
                    continue
                
                # Calculate real distance
                real_distance = self.calculate_real_distance(
                    track1.center, track2.center,
                    track1.height_pixels, track2.height_pixels
                )
                
                # Create pair key (smaller ID first)
                pair_key = (min(id1, id2), max(id1, id2))
                
                # Record distance in history - ghi l·∫°i l·ªãch s·ª≠ kho·∫£ng c√°ch gi·ªØa c·∫∑p ƒë·ªëi t∆∞·ª£ng.
                self.distance_history[pair_key].append(real_distance)
                
                # Check if distance is less than threshold
                if real_distance < self.SOCIAL_DISTANCE_THRESHOLD:
                    close_pairs.append((id1, id2, real_distance))
                    
                    # Check if they've been close for too long
                    if len(self.distance_history[pair_key]) > 0: # ki·ªÉm tra 1 c·∫∑p kho·∫£ng c√°ch ƒë√£ t·ªìn t·∫°i hay ch∆∞a - n√≥ l·∫•y c·∫£ c√°c c·∫∑p trong qu√° kh·ª© n·ªØa
                        # chia tb ra.
                        # Count frames where distance < threshold in recent history
                        close_frames = sum(1 for d in self.distance_history[pair_key] 
                                         if d < self.SOCIAL_DISTANCE_THRESHOLD)
                        
                        # Calculate time in seconds: t·ªïng th·ªùi gian (gi√¢y) m√† c·∫∑p ƒë·ªëi t∆∞·ª£ng n√†y ti·∫øp x√∫c g·∫ßn.
                        close_time = close_frames / self.current_fps
                        
                        # Issue warning if close for more than WARNING_DURATION
                        # warned_pairs ch·ª©a c√°c c·∫∑p ƒë√£ t·ª´ng b·ªã c·∫£nh b√°o < remove kh√∫c n√†y b·ªüi ID ƒë√£ c√≥ c∆° ch·∫ø reset
                        if close_time >= self.WARNING_DURATION and pair_key not in self.warned_pairs:
                            self.warned_pairs.add(pair_key)
                            print(f"\nüö® WARNING: Person ID {id1} and ID {id2} have been within {self.SOCIAL_DISTANCE_THRESHOLD}m for {close_time:.1f} seconds!")
                            print(f"   Current distance: {real_distance:.2f}m")
                else:
                    # Remove warning if they're no longer close
                    pair_key = (min(id1, id2), max(id1, id2))
                    self.warned_pairs.discard(pair_key) # x√≥a c·∫£nh b√°o khi 2 ng∆∞·ªùi ƒë√£ ko c√≤n vi ph·∫°m kho·∫£ng c√°ch
        
        # list tuple: close_pairs.append((id1, id2, real_distance))
        return close_pairs
    
    def draw_tracks(self, frame):
        # Truy·ªÅn v√†o khung h√¨nh 
        """Draw tracking results on frame"""
        # Monitor distances first, t√≠nh to√°n kho·∫£ng c√°ch hi·ªán th·ªùi c√°c ƒë·ªëi t∆∞·ª£ng c√≤n ƒëang hi·ªÉn th·ªã.
        close_pairs = self.monitor_distances()
        
        # Draw tracks: v·∫Ω c√°c bounding box
        for track_id, track in self.tracks.items():
            if track.disappeared > 0:
                continue  # Skip disappeared tracks, b·ªè qua c√°c track m√† hi·ªán th·ªùi ƒë·ªëi t∆∞·ª£ng ko ƒë∆∞·ª£c ph√°t hi·ªán.
            
            x1, y1, x2, y2 = track.bbox
            color = self.colors[track_id % len(self.colors)]
            
            # Draw bounding box
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            
            # Draw track trail
            if len(track.trail) > 1:
                for i in range(1, len(track.trail)):
                    cv2.line(frame, track.trail[i-1], track.trail[i], color, 2)
            
            # Draw label with ID
            label = f'ID: {track_id} ({track.confidence:.2f})'
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
            
            # Background for label
            cv2.rectangle(frame, (x1, y1 - label_size[1] - 10), 
                         (x1 + label_size[0], y1), color, -1)
            
            # Text
            cv2.putText(frame, label, (x1, y1 - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # Draw center point
            cv2.circle(frame, track.center, 3, color, -1)
        
        # v·∫Ω c√°c ƒë∆∞·ªùng kho·∫£ng c√°ch gi·ªØa c√°c ƒë·ªëi t∆∞·ª£ng vi ph·∫°m kho·∫£ng c√°ch
        # Draw distance lines for close pairs
        for id1, id2, distance in close_pairs:
            if id1 in self.tracks and id2 in self.tracks:
                track1 = self.tracks[id1]
                track2 = self.tracks[id2]
                
                # Draw line between centers
                cv2.line(frame, track1.center, track2.center, (0, 0, 255), 2)
                
                # Draw distance text
                mid_x = (track1.center[0] + track2.center[0]) // 2
                mid_y = (track1.center[1] + track2.center[1]) // 2
                
                distance_text = f'{distance:.1f}m'
                cv2.putText(frame, distance_text, (mid_x, mid_y),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
        
        return close_pairs
    
    def get_track_statistics(self):
        """Get tracking statistics"""
        active_tracks = sum(1 for track in self.tracks.values() if track.disappeared == 0)
        total_tracks = len(self.tracks)
        return {
            'active_tracks': active_tracks,
            'total_tracks': total_tracks,
            'next_id': self.next_id
        }

# detection d·∫°ng
# {
#    'bbox': (x1, y1, x2, y2),
#    'center': (center_x, center_y),
#    'confidence': float(conf),
#    'area': width * height,
#    'height_pixels': height  # Store pixel height for distance calculation
# }
# kh·ªüi t·∫°o 1 ƒë·ªëi t∆∞·ª£ng theo d√µi m·ªõi
class Track:
    def __init__(self, track_id, detection):
        self.id = track_id 
        self.bbox = detection['bbox']
        self.center = detection['center']
        self.confidence = detection['confidence']
        self.height_pixels = detection['height_pixels']
        self.smoothed_height = detection['height_pixels']
        self.alpha = 0.6  # EMA smoothing factor: EMA - 
        # Exponential Moving Average  ƒë∆∞·ª£c d√πng ƒë·ªÉ l√†m m∆∞·ª£t (smoothing) v·ªã tr√≠ c·ªßa c√°c ƒë·ªëi t∆∞·ª£ng ƒë∆∞·ª£c theo d√µi qua c√°c frame.
        
        self.disappeared = 0 # s·ªë frame li√™n ti·∫øp m√† ƒë·ªëi t∆∞·ª£ng ko ƒë∆∞·ª£c ph√°t hi·ªán.
        self.trail = [detection['center']] # l∆∞u v·ªã tr√≠ c√°c t√¢m ƒë·ªëi t∆∞·ª£ng, ph·ª•c v·ª• cho vi·ªác v·∫Ω c√°c ƒë∆∞·ªùng di chuy·ªÉn.
        self.max_trail_length = 20 # s·ªë l∆∞·ª£ng c√°c ƒë·ªïi n·ªëi ƒë·ªÉ v·∫Ω trail

        self.age = 0 # s·ªë frame m√† ƒë·ªëi t∆∞·ª£ng n√†y ƒë√£ t·ªìn t·∫°i, b·∫•t k·ªÉ ƒë·ªëi t∆∞·ª£ng c√≥ ƒë∆∞·ª£c nh√¨n th·∫•y hay kh√¥ng.
        # D√πng ƒë·ªÉ quy·∫øt ƒë·ªãnh khi n√†o x√≥a m·ªôt track qu√° c≈©, ho·∫∑c d√πng ƒë·ªÉ ph√¢n t√≠ch th·ªùi gian t·ªìn t·∫°i.
        
        self.total_visible_count = 1 # S·ªë frame m√† track n√†y ƒë√£ th·ª±c s·ª± "th·∫•y" ƒë∆∞·ª£c ƒë·ªëi t∆∞·ª£ng (ƒë∆∞·ª£c match th√†nh c√¥ng v·ªõi m·ªôt detection)/ c√≥ th·ªÉ ƒë·∫°i di·ªán cho m·ª©c 
        # ƒë·ªô tin c·∫≠y v·ªÅ s·ª± xu·∫•t hi·ªán c·ªßa ƒë·ªëi t∆∞·ª£ng n√†y, tin c·∫≠y c√†ng cao, tham s·ªë n√†y c√†ng l·ªõn
        
        self.consecutive_invisible_count = 0 # ƒê·∫øm s·ªë frame li√™n ti·∫øp m√† track kh√¥ng ƒë∆∞·ª£c match v·ªõi detection n√†o (m·∫•t d·∫•u).
    
    # update 1 track, H√†m n√†y d√πng ƒë·ªÉ c·∫≠p nh·∫≠t th√¥ng tin c·ªßa track m·ªói khi c√≥ m·ªôt detection m·ªõi kh·ªõp v·ªõi track n√†y.
    def update(self, detection):
        self.bbox = detection['bbox']
        self.center = detection['center']
        self.confidence = detection['confidence']

        # EMA smoothing
        self.smoothed_height = self.alpha * detection['height_pixels'] + (1 - self.alpha) * self.smoothed_height # chi·ªÅu cao ƒë√£ ƒë∆∞·ª£c l√†m m∆∞·ª£t
        self.height_pixels = self.smoothed_height # c·∫≠p nh·∫≠t chi·ªÅu cao c·ªßa ƒë·ªëi t∆∞·ª£ng

        self.disappeared = 0 # c·∫≠p nh·∫≠t l·∫°i, s·ªë khung h√¨nh li√™n ti·∫øp m√† ƒë·ªëi t∆∞·ª£ng bi·∫øn m·∫•t l√† 0
        self.age += 1 # tƒÉng tu·ªïi c·ªßa ƒë·ªëi t∆∞·ª£ng
        self.total_visible_count += 1 # tƒÉng t·ªïng s·ªë khung h√¨nh c√≥ ph√°t hi·ªán ra ƒë·ªëi t∆∞·ª£ng
        self.consecutive_invisible_count = 0 # c·∫≠p nh·∫≠t l·∫°i s·ªë l∆∞·ª£ng khung h√¨nh li√™n ti·∫øp m√† ko ph√°t hi·ªán ra ƒë·ªëi t∆∞·ª£ng.

        # Th√™m 1 ƒëi·ªÉm v√†o qu√° tr√¨nh d·ªãch chuy·ªÉn c·ªßa ƒë·ªëi t∆∞·ª£ng ƒë·ªÉ v·∫Ω c√°c ƒë∆∞·ªùng ƒëi
        self.trail.append(detection['center'])
        if len(self.trail) > self.max_trail_length: # x√≥a b·ªè b·ªõt c√°c ƒëi·ªÉm v·∫Ω trail c≈©
            self.trail.pop(0)

def process_video(video_path, tracker, output_path=None, show_window=True):
    """Process video for person tracking with distance monitoring"""
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        print(f"Error: Cannot open video file {video_path}")
        return
    
    # Get video properties
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # Set FPS for accurate timing
    tracker.set_fps(fps)
    
    print(f"Video info: {width}x{height}, {fps} FPS, {total_frames} frames")
    print(f"Distance monitoring: Social distance threshold = {tracker.SOCIAL_DISTANCE_THRESHOLD}m")
    print(f"Warning threshold: {tracker.WARNING_DURATION} seconds")
    
    # Setup video writer
    out = None
    if output_path:
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    frame_num = 0
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_num += 1
            
            # Detect persons
            detections, inference_time = tracker.detect_persons(frame)
            
            # Update tracks
            tracker.update_tracks(detections)
            
            # Draw tracking results and get close pairs
            close_pairs = tracker.draw_tracks(frame)
            
            # Get statistics
            stats = tracker.get_track_statistics()
            
            # Add information overlay
            info_text = [
                f"Frame: {frame_num}/{total_frames}",
                f"FPS: {1/inference_time:.1f}",
                f"Active IDs: {stats['active_tracks']}",
                f"Total IDs: {stats['total_tracks']}",
                f"Detections: {len(detections)}",
                f"Close pairs (<{tracker.SOCIAL_DISTANCE_THRESHOLD}m): {len(close_pairs)}",
                f"Warnings issued: {len(tracker.warned_pairs)}"
            ]
            
            for i, text in enumerate(info_text):
                cv2.putText(frame, text, (10, 30 + i * 25),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                cv2.putText(frame, text, (10, 30 + i * 25),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1)
            
            # Add legend
            legend_y = height - 100
            legend_text = [
                "Legend:",
                "Red line: Distance < 2m",
                "Red text: Distance in meters",
                "Colored trail: Person movement"
            ]
            
            for i, text in enumerate(legend_text):
                cv2.putText(frame, text, (10, legend_y + i * 20),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            # Write frame
            if out:
                out.write(frame)
            
            # Show frame
            if show_window:
                cv2.imshow("YOLOv5 Person Tracking with Distance Monitoring", frame)
                
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('s'):
                    cv2.imwrite(f"tracking_frame_{frame_num}.jpg", frame)
                    print(f"Saved frame {frame_num}")
                elif key == ord('r'):  # Reset tracking
                    tracker.tracks = {}
                    tracker.next_id = 1
                    tracker.distance_history.clear()
                    tracker.warned_pairs.clear()
                    print("Tracking reset!")
                elif key == ord('i'):  # Show info
                    print(f"\nCurrent Statistics:")
                    print(f"Active tracks: {stats['active_tracks']}")
                    print(f"Close pairs: {len(close_pairs)}")
                    print(f"Warnings issued: {len(tracker.warned_pairs)}")
                    for pair in tracker.warned_pairs:
                        print(f"  - ID {pair[0]} and ID {pair[1]}")
            
            # Progress indicator
            if frame_num % 100 == 0:
                progress = (frame_num / total_frames) * 100
                print(f"Progress: {progress:.1f}% - Active: {stats['active_tracks']}, Close pairs: {len(close_pairs)}")
    
    except KeyboardInterrupt:
        print("\nProcessing interrupted by user")
    
    finally:
        cap.release()
        if out:
            out.release()
        if show_window:
            cv2.destroyAllWindows()
        
        print(f"\nTracking complete!")
        print(f"Processed {frame_num} frames")
        print(f"Total unique persons tracked: {tracker.next_id - 1}")
        print(f"Total warnings issued: {len(tracker.warned_pairs)}")
        if tracker.warned_pairs:
            print("Warning pairs:")
            for pair in tracker.warned_pairs:
                print(f"  - ID {pair[0]} and ID {pair[1]}")

if __name__ == "__main__":
    # Example usage
    video_path = r"D:\WorkSpace\PersonPath22\tracking-dataset\dataset\dataset1\raw_data\uid_vid_00035.mp4"
    
    if os.path.exists(video_path):
        tracker = PersonTracker(confidence_threshold=0.4)
        process_video(video_path, tracker)
    else:
        print("Please update the video_path or use command line arguments")
        print("Usage: python script.py --video path/to/video.mp4")